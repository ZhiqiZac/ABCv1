
# Set up and run this Streamlit App
import streamlit as st
from logics.rag import process_user_message, process_user_message2
import pandas as pd
from openai import OpenAI
import tiktoken

#load passwords from env file for security
import os
from dotenv import load_dotenv

'''
if load_dotenv('.env'):
   # for local development
   OPENAI_KEY = os.getenv('OPENAI_API_KEY')
else:
   OPENAI_KEY = st.secrets['OPENAI_API_KEY']

# Pass the API Key to the OpenAI Client
client = OpenAI(api_key=OPENAI_KEY)

'''
# region <--------- Streamlit App Configuration --------->
st.set_page_config(
    layout="centered",
    page_title="My Streamlit App"
)
# endregion <--------- Streamlit App Configuration --------->

st.title("LLM Bot that responds to queries on HDB resale")

form = st.form(key="form")
form.subheader("Prompt")

user_prompt = form.text_area("Enter your prompt here", height=200)

if form.form_submit_button("Submit"):
    #st.toast(f"User Input Submitted - {user_prompt}") #this 
    response = process_user_message(user_prompt)

    print(f"User Input is {user_prompt}")
    st.write(response) # <--- This displays the response generated by the LLM onto the frontend ðŸ†•